# Visually Rich Documents (VRD)

## A list of recent papers on various tasks for Visually Rich Documents

Curated by: [Ritesh Sarkhel](https://sarkhelritesh.github.io/)

*Disclaimer: This is **not** an exhaustive list. If you find a relavent paper missing and think it should feature on this list, please submit a pull request or [email me](mailto:sarkhel.5@osu.edu). Your contribution will help us keep this page up-to-date!*

## Content Overview
- [Paper List](#paper-list)
    - [Information Extraction](####information-extraction)
    - [Language Model](####language-model)
    - [Layout Analysis](####layout-analysis)
    - [Document Classification](####document-classification)
    - [Retrieval](####retrieval)

#### Information Extraction
1. [Chargrid: Towards Understanding 2D Documents](https://www.aclweb.org/anthology/D18-1476.pdf/), Anoop R Katti, Christian Reisswig, Cordula Guder, Sebastian Brarda, Steffen Bickel, Johannes Hohne, and Jean Baptiste Faddoul, *EMNLP 2018*
2. [VisualWordGrid: Information Extraction From Scanned Documents Using A Multimodal Approach](https://arxiv.org/pdf/2010.02358.pdf), Mohamed Kerroumi, Othmane Sayem, and Aymen Shabou, *Pre-print*
3. [BERTgrid: Contextualized Embedding for 2D Document Representation and Understanding](https://openreview.net/pdf?id=H1gsGaq9US), Timo I. Denk, Christian Reisswig, *Workshop on Document Intelligence at NeurIPS 2019*
4. [Graph Convolution for Multimodal Information Extraction from Visually Rich Documents](https://www.aclweb.org/anthology/N19-2005.pdf), Xiaojing Liu, Feiyu Gao, Qiong Zhang, and Huasha Zhao, *NAACL-HLT 2019*
































    
#### Language-Model
